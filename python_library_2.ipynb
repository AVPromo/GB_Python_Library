{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Вычисления с помощью Numpy**"
      ],
      "metadata": {
        "id": "jc6qGfyNXqeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте массив Numpy под названием a размером 5x2, то есть состоящий из 5 строк\n",
        "и 2 столбцов. Первый столбец должен содержать числа 1, 2, 3, 3, 1, а второй - числа 6,\n",
        "8, 11, 10, 7. Будем считать, что каждый столбец - это признак, а строка - наблюдение.\n",
        "Затем найдите среднее значение по каждому признаку, используя метод mean массива\n",
        "Numpy. Результат запишите в массив mean_a, в нем должно быть 2 элемента."
      ],
      "metadata": {
        "id": "jDsaNnboTHPj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV2ozWNpS8t3",
        "outputId": "b1ce2034-bf39-4596-b2b7-18c881d0fbfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.  8.4]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Создаем массив Numpy с заданными значениями\n",
        "a = np.array([[1, 6], [2, 8], [3, 11], [3, 10], [1, 7]])\n",
        "\n",
        "# Находим среднее значение для каждого столбца (признака)\n",
        "mean_a = a.mean(axis=0)\n",
        "\n",
        "# Выводим результат\n",
        "print(mean_a)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вычислите массив a_centered, отняв от значений массива “а” средние значения\n",
        "соответствующих признаков, содержащиеся в массиве mean_a. Вычисление должно\n",
        "производиться в одно действие. Получившийся массив должен иметь размер 5x2."
      ],
      "metadata": {
        "id": "fewaC3uoT7JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Умножаем каждую строку массива 'a' на вектор обратных значений средних\n",
        "a_centered = a - mean_a\n",
        "\n",
        "# Выводим получившийся массив\n",
        "print(a_centered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLyQKDExT8K2",
        "outputId": "66ec8ae5-7118-4050-be74-b29ba780c7de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.  -2.4]\n",
            " [ 0.  -0.4]\n",
            " [ 1.   2.6]\n",
            " [ 1.   1.6]\n",
            " [-1.  -1.4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите скалярное произведение столбцов массива a_centered. В результате должна\n",
        "получиться величина _centered_spa. Затем поделите a_centered_sp на N-1, где N - число наблюдений."
      ],
      "metadata": {
        "id": "4m18SA1BUbY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Число наблюдений\n",
        "N = a_centered.shape[0]\n",
        "\n",
        "# Вычисляем произведение централизованных столбцов\n",
        "centered_spa = np.sum(a_centered[:, 0]  *  a_centered[:, 1])\n",
        "\n",
        "# Делим на N-1 для корректировки оценки\n",
        "centered_spa /= (N - 1)\n",
        "\n",
        "print(centered_spa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLq2vlj8Ua_I",
        "outputId": "66567af8-91db-491f-9daf-4fcf672cb430"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверьте получившееся число, вычислив ковариацию еще одним способом - с\n",
        "помощью функции np.cov. В качестве аргумента m функция np.cov должна принимать\n",
        "транспонированный массив “a”. В получившейся ковариационной матрице (массив Numpy размером 2x2) искомое значение ковариации будет равно элементу в строке с индексом 0 и столбце с индексом 1."
      ],
      "metadata": {
        "id": "JYKsvZJvXV0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1, 6], [2, 8], [3, 11], [3, 10], [1, 7]])\n",
        "# Транспонируем массив 'a'\n",
        "a_t = a.T\n",
        "\n",
        "# Вычисляем ковариационную матрицу\n",
        "cov_matrix = np.cov(a_t)\n",
        "\n",
        "# Выводим элемент ковариационной матрицы в строке 0 и столбце 1\n",
        "print(cov_matrix[0, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlbEbh1UUa8Y",
        "outputId": "c42d2f8c-ee43-435e-f6ae-99330c5ac5c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Работа с данными в Pandas**"
      ],
      "metadata": {
        "id": "dNTuVIxlX0gG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируйте библиотеку Pandas и дайте ей псевдоним pd. Создайте датафрейм authors со столбцами author_id и author_name, в которых соответственно содержатся данные: [1, 2, 3] и ['Тургенев', 'Чехов', 'Островский'].\n",
        "Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно содержатся данные: [1, 1, 1, 2, 2, 3, 3], ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'], [500, 400, 300, 350, 450, 600, 200]"
      ],
      "metadata": {
        "id": "B8VbLLGqX58W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Создаем датафрейм authors\n",
        "authors = pd.DataFrame({'author_id': [1, 2, 3], 'author_name': ['Тургенев', 'Чехов', 'Островский']})\n",
        "\n",
        "# Создаем датафрейм books\n",
        "books = pd.DataFrame({'author_id': [1, 1, 1, 2, 2, 3, 3],\n",
        "                     'book_title': ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
        "                     'price': [500, 400, 300, 350, 450, 600, 200]})"
      ],
      "metadata": {
        "id": "mfO6-YMeYgM3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получите датафрейм authors_price, соединив дата фреймы authors и books по полю author_id."
      ],
      "metadata": {
        "id": "lcZtuK-MYp8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Соединяем датафреймы authors и books по полю author_id\n",
        "authors_price = pd.merge(authors, books, on='author_id')\n",
        "\n",
        "# Выводим результат\n",
        "print(authors_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2bMMZbkYxVn",
        "outputId": "71f5ca85-3503-4f85-b84c-b0a8f11e6f49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   author_id author_name            book_title  price\n",
            "0          1    Тургенев           Отцы и дети    500\n",
            "1          1    Тургенев                 Рудин    400\n",
            "2          1    Тургенев     Дворянское гнездо    300\n",
            "3          2       Чехов      Толстый и тонкий    350\n",
            "4          2       Чехов       Дама с собачкой    450\n",
            "5          3  Островский                 Гроза    600\n",
            "6          3  Островский  Таланты и поклонники    200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте датафрейм top5, в котором содержатся строки из authors_price с пятью самыми дорогими книгами."
      ],
      "metadata": {
        "id": "aL6gtsmGZM_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Сортируем датафрейм authors_price по цене в убывающем порядке\n",
        "sorted_books = authors_price.sort_values('price', ascending=False)\n",
        "\n",
        "# Создаем датафрейм top5, содержащий первые пять строк отсортированного датафрейма\n",
        "top5 = sorted_books.head(5)\n",
        "\n",
        "# Выводим результат\n",
        "print(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqsgq2AfZWC3",
        "outputId": "4a4a0245-b686-41ae-c623-459d7b7ebcf7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   author_id author_name        book_title  price\n",
            "5          3  Островский             Гроза    600\n",
            "0          1    Тургенев       Отцы и дети    500\n",
            "4          2       Чехов   Дама с собачкой    450\n",
            "1          1    Тургенев             Рудин    400\n",
            "3          2       Чехов  Толстый и тонкий    350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat должны быть четыре столбца: author_name, min_price, max_price и mean_price, в которых должны содержаться соответственно имя автора, минимальная, максимальная и средняя цена на книги этого автора."
      ],
      "metadata": {
        "id": "qerdVfRGZucX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем датафрейм authors_stat\n",
        "authors_stat = authors_price.groupby('author_name').agg({'price': ['min', 'max', 'mean']}).reset_index()\n",
        "authors_stat.columns = ['author_name', 'min_price', 'max_price', 'mean_price']\n",
        "\n",
        "# Выводим результат\n",
        "print(authors_stat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rYVVbCvgIUO",
        "outputId": "f8ed3851-e0c3-4b67-b735-bc3e9b1a0b46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  author_name  min_price  max_price  mean_price\n",
            "0  Островский        200        600       400.0\n",
            "1    Тургенев        300        500       400.0\n",
            "2       Чехов        350        450       400.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Просмотрите документацию по функции pd.pivot table с помощью вопросительного знака."
      ],
      "metadata": {
        "id": "PrA8PfPnjbDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Просматриваем документацию по функции pd.pivot_table\n",
        "help(pd.pivot_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTeU0NWPjavE",
        "outputId": "bccc8f2c-6747-45dc-bade-3cd89f236bb3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function pivot_table in module pandas.core.reshape.pivot:\n",
            "\n",
            "pivot_table(data: 'DataFrame', values=None, index=None, columns=None, aggfunc: 'AggFuncType' = 'mean', fill_value=None, margins: 'bool' = False, dropna: 'bool' = True, margins_name: 'Hashable' = 'All', observed: 'bool' = False, sort: 'bool' = True) -> 'DataFrame'\n",
            "    Create a spreadsheet-style pivot table as a DataFrame.\n",
            "    \n",
            "    The levels in the pivot table will be stored in MultiIndex objects\n",
            "    (hierarchical indexes) on the index and columns of the result DataFrame.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : DataFrame\n",
            "    values : list-like or scalar, optional\n",
            "        Column or columns to aggregate.\n",
            "    index : column, Grouper, array, or list of the previous\n",
            "        If an array is passed, it must be the same length as the data. The\n",
            "        list can contain any of the other types (except list).\n",
            "        Keys to group by on the pivot table index.  If an array is passed,\n",
            "        it is being used as the same manner as column values.\n",
            "    columns : column, Grouper, array, or list of the previous\n",
            "        If an array is passed, it must be the same length as the data. The\n",
            "        list can contain any of the other types (except list).\n",
            "        Keys to group by on the pivot table column.  If an array is passed,\n",
            "        it is being used as the same manner as column values.\n",
            "    aggfunc : function, list of functions, dict, default numpy.mean\n",
            "        If list of functions passed, the resulting pivot table will have\n",
            "        hierarchical columns whose top level are the function names\n",
            "        (inferred from the function objects themselves)\n",
            "        If dict is passed, the key is column to aggregate and value\n",
            "        is function or list of functions. If ``margin=True``,\n",
            "        aggfunc will be used to calculate the partial aggregates.\n",
            "    fill_value : scalar, default None\n",
            "        Value to replace missing values with (in the resulting pivot table,\n",
            "        after aggregation).\n",
            "    margins : bool, default False\n",
            "        If ``margins=True``, special ``All`` columns and rows\n",
            "        will be added with partial group aggregates across the categories\n",
            "        on the rows and columns.\n",
            "    dropna : bool, default True\n",
            "        Do not include columns whose entries are all NaN. If True,\n",
            "        rows with a NaN value in any column will be omitted before\n",
            "        computing margins.\n",
            "    margins_name : str, default 'All'\n",
            "        Name of the row / column that will contain the totals\n",
            "        when margins is True.\n",
            "    observed : bool, default False\n",
            "        This only applies if any of the groupers are Categoricals.\n",
            "        If True: only show observed values for categorical groupers.\n",
            "        If False: show all values for categorical groupers.\n",
            "    \n",
            "    sort : bool, default True\n",
            "        Specifies if the result should be sorted.\n",
            "    \n",
            "        .. versionadded:: 1.3.0\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    DataFrame\n",
            "        An Excel style pivot table.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    DataFrame.pivot : Pivot without aggregation that can handle\n",
            "        non-numeric data.\n",
            "    DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
            "        optionally leaving identifiers set.\n",
            "    wide_to_long : Wide panel to long format. Less flexible but more\n",
            "        user-friendly than melt.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
            "    ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
            "    ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
            "    ...                          \"one\", \"one\", \"two\", \"two\"],\n",
            "    ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
            "    ...                          \"small\", \"large\", \"small\", \"small\",\n",
            "    ...                          \"large\"],\n",
            "    ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
            "    ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
            "    >>> df\n",
            "         A    B      C  D  E\n",
            "    0  foo  one  small  1  2\n",
            "    1  foo  one  large  2  4\n",
            "    2  foo  one  large  2  5\n",
            "    3  foo  two  small  3  5\n",
            "    4  foo  two  small  3  6\n",
            "    5  bar  one  large  4  6\n",
            "    6  bar  one  small  5  8\n",
            "    7  bar  two  small  6  9\n",
            "    8  bar  two  large  7  9\n",
            "    \n",
            "    This first example aggregates values by taking the sum.\n",
            "    \n",
            "    >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
            "    ...                        columns=['C'], aggfunc=np.sum)\n",
            "    >>> table\n",
            "    C        large  small\n",
            "    A   B\n",
            "    bar one    4.0    5.0\n",
            "        two    7.0    6.0\n",
            "    foo one    4.0    1.0\n",
            "        two    NaN    6.0\n",
            "    \n",
            "    We can also fill missing values using the `fill_value` parameter.\n",
            "    \n",
            "    >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
            "    ...                        columns=['C'], aggfunc=np.sum, fill_value=0)\n",
            "    >>> table\n",
            "    C        large  small\n",
            "    A   B\n",
            "    bar one      4      5\n",
            "        two      7      6\n",
            "    foo one      4      1\n",
            "        two      0      6\n",
            "    \n",
            "    The next example aggregates by taking the mean across multiple columns.\n",
            "    \n",
            "    >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
            "    ...                        aggfunc={'D': np.mean, 'E': np.mean})\n",
            "    >>> table\n",
            "                    D         E\n",
            "    A   C\n",
            "    bar large  5.500000  7.500000\n",
            "        small  5.500000  8.500000\n",
            "    foo large  2.000000  4.500000\n",
            "        small  2.333333  4.333333\n",
            "    \n",
            "    We can also calculate multiple types of aggregations for any given\n",
            "    value column.\n",
            "    \n",
            "    >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
            "    ...                        aggfunc={'D': np.mean,\n",
            "    ...                                 'E': [min, max, np.mean]})\n",
            "    >>> table\n",
            "                      D   E\n",
            "                   mean max      mean  min\n",
            "    A   C\n",
            "    bar large  5.500000   9  7.500000    6\n",
            "        small  5.500000   9  8.500000    8\n",
            "    foo large  2.000000   5  4.500000    4\n",
            "        small  2.333333   6  4.333333    2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте новый столбец в датафрейме authors_price под названием cover, в нем будут располагаться данные о том, какая обложка у данной книги - твердая или мягкая. В этот столбец поместите данные из следующего списка:\n",
        "['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая'].\n",
        "Для каждого автора посчитайте суммарную стоимость книг в твердой и мягкой обложке. Используйте для этого функцию pd.pivot_table. При этом столбцы должны называться \"твердая\" и \"мягкая\", а индексами должны быть фамилии авторов. Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy.\n",
        "\n",
        "Назовите полученный датасет book_info и сохраните его в формат pickle под названием \"book_info.pkl\". Затем загрузите из этого файла датафрейм и назовите его book_info2. Удостоверьтесь, что датафреймы book_info и book_info2 идентичны."
      ],
      "metadata": {
        "id": "yBX2dZT-i-Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавляем столбец cover с данными о типе обложки\n",
        "authors_price['cover'] = ['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']\n",
        "\n",
        "# Считаем суммарную стоимость книг в твердой и мягкой обложке для каждого автора\n",
        "book_info = pd.pivot_table(authors_price, values='price', index='author_name', columns='cover', aggfunc=np.sum, fill_value=0)\n",
        "\n",
        "# Сохраняем датафрейм в формат pickle\n",
        "book_info.to_pickle(\"book_info.pkl\")\n",
        "\n",
        "# Загружаем датафрейм из файла .pkl\n",
        "book_info2 = pd.read_pickle(\"book_info.pkl\")\n",
        "\n",
        "# Проверяем идентичность датафреймов\n",
        "if book_info.equals(book_info2):\n",
        "    print(\"Датафреймы book_info и book_info2 идентичны.\")\n",
        "else:\n",
        "    print(\"Датафреймы book_info и book_info2 НЕ идентичны.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn8lzISOj06H",
        "outputId": "54f9c00a-bd1f-4214-ab6e-562d20549f39"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Датафреймы book_info и book_info2 идентичны.\n"
          ]
        }
      ]
    }
  ]
}